Command:        mpirun -np 2 ./xhpl
Resources:      1 node (2 physical, 2 logical cores per node)
Memory:         4 GiB per node
Tasks:          2 processes
Machine:        aposta-VirtualBox
Start time:     周五 8月 11 2017 12:43:12 (UTC+08)
Total time:     315 seconds (about 5 minutes)
Full path:      /home/aposta/sc17/hpl-2.2/bin/openBlas

Summary: xhpl is Compute-bound in this configuration
Compute:                                     70.3% |======|
MPI:                                         29.6% |==|
I/O:                                          0.0% |
This application run was Compute-bound. A breakdown of this time and advice for investigating further is in the CPU section below. 
As little time is spent in MPI calls, this code may also benefit from running at larger scales.

CPU:
A breakdown of the 70.3% CPU time:
Scalar numeric ops:                           8.0% ||
Vector numeric ops:                          34.0% |==|
Memory accesses:                             41.0% |===|
The CPU performance appears well-optimized for numerical computation. The biggest gains may now come from running at larger scales.
Significant time is spent on memory accesses. Use a profiler to identify time-consuming loops and check their cache performance.

MPI:
A breakdown of the 29.6% MPI time:
Time in collective calls:                     0.3% ||
Time in point-to-point calls:                99.7% |=========|
Effective process collective rate:            0.00 bytes/s
Effective process point-to-point rate:        71.5 MB/s
Most of the time is spent in point-to-point calls with a low transfer rate. This can be caused by inefficient message sizes, such as many small messages, or by imbalanced workloads causing processes to wait.

I/O:
A breakdown of the 0.0% I/O time:
Time in reads:                                0.0% |
Time in writes:                               0.0% |
Effective process read rate:                  0.00 bytes/s
Effective process write rate:                 0.00 bytes/s
No time is spent in I/O operations. There's nothing to optimize here!

Threads:
A breakdown of how multiple threads were used:
Computation:                                 19.5% |=|
Synchronization:                             80.5% |=======|
Physical core utilization:                   94.0% |========|
System load:                                191.6% |==================|
Significant time is spent synchronizing threads. Check which locks cause the most overhead with a profiler.
The system load is high. Ensure background system processes are not running.

Memory:
Per-process memory usage may also affect scaling:
Mean process memory usage:                     175 MiB
Peak process memory usage:                     188 MiB
Peak node memory usage:                      54.0% |====|
The peak node memory usage is modest. Running with fewer MPI processes and more data on each process may be more efficient.

Energy:
A breakdown of how energy was used:
CPU:                                      not supported
System:                                   not supported
Mean node power:                          not supported
Peak node power:                          not supported
Energy metrics are not available on this system.
CPU metrics are not supported (no intel_rapl module)

